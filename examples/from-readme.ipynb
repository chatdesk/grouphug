{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b50547-7eca-48e4-b73d-bb046ac882aa",
   "metadata": {},
   "source": [
    "# This example is mainly to test and run the short example in the README file\n",
    "Other examples have a little more explanation. However, the `compute_classification_metrics` function may be worth a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96963a2d-60ce-4326-b1e6-18c4c64cba1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")  # ensure we can run examples as-is in the package's poetry env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4a4165-5e43-4a8c-b6ae-ec0518b6c757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, TrainingArguments\n",
    "\n",
    "from grouphug import AutoMultiTaskModel, ClassificationHeadConfig, DatasetFormatter, LMHeadConfig, MultiTaskTrainer\n",
    "from utils import compute_classification_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e312f42-9c81-4ce0-862d-b52c00ac28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some data. 'label' gets renamed in huggingface, so is better avoided as a feature name.\n",
    "task_one = load_dataset(\"tweet_eval\", \"emoji\").rename_column(\"label\", \"tweet_label\")\n",
    "both_tasks = pd.DataFrame({\"text\": [\"yay :)\", \"booo!\"], \"sentiment\": [\"pos\", \"neg\"], \"tweet_label\": [0, 14]})\n",
    "\n",
    "# create a tokenizer\n",
    "base_model = \"prajjwal1/bert-tiny\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "# preprocess your data: tokenization, preparing class variables\n",
    "formatter = DatasetFormatter().tokenize().encode(\"sentiment\")\n",
    "# data converted to a DatasetCollection: essentially a dict of DatasetDict\n",
    "data = formatter.apply({\"one\": task_one, \"both\": both_tasks}, tokenizer=tokenizer, test_size=0.05)\n",
    "\n",
    "# define which model heads you would like\n",
    "head_configs = [\n",
    "    LMHeadConfig(weight=0.1),  # default is BERT-style masked language modelling\n",
    "    ClassificationHeadConfig.from_data(data, \"sentiment\"),  # detects dimensions and type\n",
    "    ClassificationHeadConfig.from_data(data, \"tweet_label\"),  # detects dimensions and type\n",
    "]\n",
    "# create the model, optionally saving the tokenizer and formatter along with it\n",
    "model = AutoMultiTaskModel.from_pretrained(base_model, head_configs, formatter=formatter, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f6b3bd-c570-48c1-a3f5-b19cc56ba521",
   "metadata": {},
   "source": [
    "## Create the trainer and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94eca6-980a-40e3-acb6-98eba17eaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MultiTaskTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_data=data[:, \"train\"],\n",
    "    eval_data=data[[\"one\"], \"test\"],  # using a list as first key to keep this as a dict\n",
    "    eval_heads={\"one\": [\"tweet_label\"]},  # limit evaluation to one classification task\n",
    "    compute_metrics=compute_classification_metrics,\n",
    "    args=TrainingArguments(output_dir=\"../output\", evaluation_strategy=\"epoch\",save_steps=5000),\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78022963-3594-46cb-a3f5-e305c42146e9",
   "metadata": {},
   "source": [
    "## Example inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7af27a-533b-4c6b-853b-7495a5ccc5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict({\"text\": \"this is nice\"}) # single sample inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee13f85-49e9-4b00-81ee-94f47088db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(both_tasks)  # dataframe inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11ebc22-92f7-4b4c-b3a5-1e20680ddf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(data[\"one\", \"test\"])  # dataset inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
